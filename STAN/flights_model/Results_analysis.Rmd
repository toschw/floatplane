---
title: "STAN_results"
author: "Tobias Schwoerer"
date: "March 25, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

This code was used to prepare a .csv result file for further ArcGIS data visualization of the datafit.csv results file generated by the 
flights ration model that I ran in STAN.

```{r}
library(dplyr)
library(tidyr)
library(data.table)
library(purrr)
library(jsonlite)
library(geojson)
library(leaflet)
library(ggplot2)
library(RColorBrewer)
library(leaflet.minicharts)
```

Creating a reference table with destination-specific information
```{r}
#importing reference table for destination information and association to theta[id]
ref <- read.csv("Data/Destinations091916_4.csv", stringsAsFactors = FALSE)
lakes <- read.dbf("D:/Dropbox/DATA/2015_Schwoerer_floatplane_survey/Elodea_Fetch_Elevation/Elodea_Fetch_Elev.dbf")
l#adding Sucker Lake as a new ElodeaDest = 1
ref$ElodeaDest <- with(ref,ifelse(UniqueID=="Lk_312858",1,ElodeaDest))

#adding a variable about suspected Floatplane introductions, SusFPintro
FPintro <- read.csv("Data/SusFPintro.csv", stringsAsFactors = F)
#drop name column
FPintro <- select(FPintro, UniqueID, SusFPintro)
ref2 <- ref%>%
  left_join(FPintro, by='UniqueID')
ref2$SusFPintro <- ref2$SusFPintro %>%
  replace_na(0)

#cleaning up some unnecessary columns
keepCol <- c("Destina_11","WithinNPS_","WithinRefu","HUC8","Suitab","HUC6","Name","GMU","UniqueID","Fetch_m","ElevMIN","ElevMAX","Dest1Lat","Dest2Long","DestName","X25th","median","X75th","medianrank","Dest_sqkm","modelID","ElodeaDest", "SusFPintro")
ref3 <- dplyr::select(ref2, keepCol)

#there are multiple lat long pairs possible for each UniqueID, but since the analysis is by destination waterbody (among all 727 identified) we chose just one lat long per UniqueID. extracting unique records so each destination is represented in each row
#So we used 
ref3 = ref3[!duplicated(ref3$UniqueID),]
#Instead of:
#IDs <- unique(ref$UniqueID)
#ref <- subset(ref, UniqueID %in% IDs)

#renaming columns
setnames(ref3, old=c("Destina_11","WithinNPS_","Name","Dest1Lat","Dest2Long"), new=c("DestType", "WithinNPS","RegionName","Lat","Long"))
#ordering by modelID number shown in [] brackets
ref3$LakeID <- gsub(".*\\[|\\]", "", ref3$modelID) 
ref3$LakeID <- as.numeric(ref3$LakeID)
              
ref3 = ref3[order(ref3[,'LakeID']),]
```

Creating our own fit summary from datafit object, ignoring the fit_summary1.csv file for now
```{r}
#setwd("D:/ANALYSIS_R/floatplane")
data <- read.csv("STAN/flights_model/datafit.csv")

#subsetting data
draws <- select(data,2:728)
abavg <- select(data,734:1460 ) 
ranks <- select(data,1461:2187)
```


25th, median, 75th percentile
```{r}
library(tidyverse)
drawsR <- draws%>%
    summarise_all(funs(list(quantile(., probs = c(0.25, 0.5, 0.75))))) %>%
    unnest %>%
    transpose %>%
    setNames(., c('p25th', 'p50th', 'p75th')) %>%
    map_df(unlist) %>%
    bind_cols(data.frame(vars = names(draws)), .)
setnames(drawsR, old=c("vars"),new=c("vars3"))
```

variance of the posterior
```{r}
varR <- draws%>%
  summarise_each(var)%>%
    unnest %>%
    transpose %>%
    setNames(., c('variance')) %>%
    map_df(unlist) %>%
    bind_cols(data.frame(vars = names(draws)), .)
setnames(varR, old=c("vars"),new=c("vars4"))
```

Subset of destinations with above average probability of infestation through floatplanes
```{r}
abavgR <- abavg%>%
    summarise_each(mean)%>%
    unnest %>%
    transpose %>%
    setNames(., c('mean_abavg')) %>%
    map_df(unlist) %>%
    bind_cols(data.frame(vars = names(abavg)), .)
setnames(abavgR, old=c("vars"),new=c("vars1"))
```

Risk rank among the 727 identified waterbodies
```{r}
ranksR <- ranks%>%
    summarise_each(mean)%>%
    unnest %>%
    transpose %>%
    setNames(., c('mean_rank')) %>%
    map_df(unlist) %>%
    bind_cols(data.frame(vars = names(ranks)), .)
setnames(ranksR, old=c("vars"),new=c("vars2"))
```

Combining results and adding destination specific information
```{r}
fitS <- read.csv("STAN/flights_model/fit_summary1.csv")


results <- cbind(drawsR, abavgR,ranksR,varR,ref3)
#dropping a few unnecessary columns

results <- results%>%
  select(-vars1, -vars2, -vars3, -vars4)
```

Comparing the risk ranks between previous analysis using pilot ratios vs. flight ratios
```{r}
#medianrank is from previous pilot ratios, mean_rank is the risk rank based on flight frequencies
with(results,(plot(medianrank, mean_rank,xlim=c(0,727), ylim=c(0,727),xlab="ranks pilot-ratio-model",
ylab="ranks flight-ratio-model")))
abline(a=0,b=1, col="blue")
title("Comparing pilot ratio to flight ratio models")
```

#Scatterplot between p50th and variance 
```{r}
library(ggplot2)
library(ggrepel)
library(dplyr)
library(tidyr)
results2 <- results%>%
  select(-X25th, -median, -X75th, -medianrank)
results2$inv_variance = 1/results2$variance
#creating log of inverse variance for easier plotting
results2$lginvar <- log(results2$inv_variance)
#creating new name variable to eliminate unknown lakes cluttering the labels
results2$DestName2<- with(results2, ifelse(DestName=="<unknown/unnamed>","",DestName))
#fixing names for Kahiltna Glacier Lake
results2$DestName2<- with(results2, ifelse(DestName2=="Kahiltna Glacier","Kahiltna Gl. Lake",DestName2))
#creating risk category / quadrants in scatterplot
results2$riskCat <- with(results2, ifelse(p50th>0.25&lginvar<7.3046,1,ifelse(p50th>0.25&lginvar>=7.3046,2,ifelse(p50th<0.25&lginvar<7.3046,4,3))))
#creating subsets
highRisk <- subset(results2, riskCat==1)
highestRisk <- subset(highRisk, p50th>0.9)
results2$highestRisk <- with(results2, ifelse(p50th>0.9&lginvar<7.3046,"yes","no"))
```

#Plots with 4 risk quandrangles
```{r}
p<-ggplot(results2, aes(x=lginvar, y=p50th)) +
  annotate("rect", xmin = 3, xmax = 7.3046, ymin = 0.9, ymax = 1, fill= "#bd0026")+
  annotate("rect", xmin = 3, xmax = 7.3046, ymin = 0.25, ymax = 0.9, fill= "#f03b20")+
  annotate("rect", xmin = 7.3046, xmax = 14.5, ymin = 0.25, ymax = 1, fill= "#fd8d3c")+
  annotate("rect", xmin = 3, xmax = 7.3046, ymin = 0, ymax = 0.25, fill= "#ffffb2")+
  annotate("rect", xmin = 7.3046, xmax = 14.5, ymin = 0, ymax = 0.25, fill= "#fecc5c")+
  xlim(3,14.5)+
  ylim(0,1)+
  geom_point() +
  theme_classic() +
  geom_vline(xintercept = 7.3046) + geom_hline(yintercept = 0.25)+
    labs(x="log(inverse variance)", y="median posterior probability of introduction")+
  annotate(geom="text", x=3.5, y=0.95, label="A", color="black", fontface ="bold", size =5)+
  annotate(geom="text", x=3.5, y=0.85, label="B", color="black",fontface ="bold", size =5)+
  annotate(geom="text", x=3.5, y=0.2, label="E", color="black",fontface ="bold", size =5)+
  annotate(geom="text", x=14, y=0.95, label="C", color="black",fontface ="bold", size =5)+
  annotate(geom="text", x=14, y=0.2, label="D", color="black",fontface ="bold", size =5)
p

hR<-ggplot(highRisk, aes(x=lginvar, y=p50th)) +
  geom_point() +
  #lims(x=c(1,10),y=c(1,10)) +
  theme_minimal()
hR

plot <-ggplot(highestRisk,aes(x=lginvar, y=p50th, color = ElodeaDest) ) +
  #coord_polar(theta = "x") +
  geom_point() +
  theme_classic() +
  geom_text_repel(aes(label=DestName2))+
  labs(x="log(inverse variance)", y="median posterior probability of introduction")+
 guides(fill=FALSE, color=FALSE)
plot

proportions <- results2%>%
  group_by(riskCat)%>%
  count()
```

Dropping pilot ratio model results from results, writing to csv file
```{r}
#adding raw data
rawFlights <- read.csv("STAN/floatplanedata4.csv", stringsAsFactors = F)
#make sure keys are both integer, then joining
results2$LakeID <- as.integer(results2$LakeID)
results3 <- results2%>%
  left_join(rawFlights,by='LakeID')


#adding names for HUC8 units
huc <- read.csv("Data/huc_codes.csv")
results3$HUC8 <- as.integer(results3$HUC8)
results3 <- results3%>%
  left_join(huc,by=c('HUC8'='code'))

#drop columns
results3 <- select(results3,-DestName2,-modelID.x, -ElodeaDest, -SusFPintro, -inv_variance, -lginvar, -modelID.y, -pilots, -epilots, -flights, -eflights, -weflights, -name, -wflights)

write.csv(results3, file="D:/Dropbox/DATA/2015_Schwoerer_floatplane_survey/STANresults.csv",row.names = FALSE)
```

graphing and mapping
```{r}
#creating subset of destinations with a median prob >0.8
lakes <- subset(results3, p50th>0.8)
# Create a continuous palette function
pal <- colorNumeric(
  palette = "Reds",
  domain = lakes$p50th)
#Interactive layer display
clickMap1 <- leaflet(lakes, width = "100%", height = 1000) %>%
  setView(-147.3, 62.0, zoom = 5)%>%
  #Base groups
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$Esri.WorldTopoMap, group = "Esri Topo")%>%
  addProviderTiles(providers$Esri.WorldImagery, group = "Esri Image")%>%
  #Overlay groups
  addCircleMarkers(lat = ~Lat, lng = ~Long, ~p50th, radius = ~inv_variance/1000, stroke=T,  
                   color= ~pal(p50th), fillOpacity = 1, weight = 25)%>%
    #Layers control
  addLayersControl(
    baseGroups = c("Esri Topo", "Esri Image","OpenStreetMap")
      )%>%
  addLegend("topright",values= ~p50th, pal=pal, title="median probability")
clickMap1
```


Validation of the model with elodea presence
```{r}
elodeaLakes <- results3%>%
  group_by(SusFPintro)%>%
    summarise(countHigh = sum(ifelse(p50th>0.5,1,0)),
              countLow = sum(ifelse(p50th<=0.5,1,0))) 
              
eLakes <- subset(results3, SusFPintro==1)
eLakes <- select(eLakes, DestName, variance, inv_variance, p50th, mean_abavg, flights,eflights )
```


Risk-ordered subset of NPS lakes at risk
```{r}
NPS <- subset(results3,WithinNPS==1)

#risk order
NPS2 <- NPS%>%
  filter(p50th >0.5)%>%
  arrange(desc(p50th),desc(inv_variance))
NPS2$RiskIndex <- seq.int(nrow(NPS2))
write.csv(NPS2, file="D:/Dropbox/DATA/2015_Schwoerer_floatplane_survey/nps_lakes_modeled.csv",row.names = FALSE)
```


#Creating table of results for important floatplane bases
```{r}
STANresults <- read.csv("D:/Dropbox/DATA/2015_Schwoerer_floatplane_survey/STANresults.csv",stringsAsFactors=FALSE)
FAAbases <- read.csv("Data/FAAbases.csv", stringsAsFactors = FALSE)
bases <- FAAbases[,2]
basesResults <- subset(STANresults, UniqueID %in% bases)
write.csv(basesResults, file="D:/Dropbox/CURRENT_PROJECTS/MANUSCRIPTS/J_of_Envi_Mgmt/basesResults.csv",row.names = FALSE)
```

Comparing median posterior estimate with raw introduction rates
```{r}
count <- sdata%>%
  dplyr::transmute(intro, eflights/flights)
```